---
title: "Analysis of interest rate in Brazil"
Author: "Pedro Philippi Araujo"
format: 
  html: 
    embed: true
execute:
  environment: python3
jupyter: python3
kernel: python3
---



## Introduction

The purpose of this notebook is to acquire and understand data from the Banco Central do Brasil (Brazil Central Bank) in order to create a model prediction for interest rates.


## Data Acquisition

We are going to download through url request the following series of data:

433 - Índice nacional de preços ao consumidor-amplo (IPCA) -- National index of ample-consumer prices: Measures inflation.

11753 - Índice da taxa de câmbio real (IPCA) -- Exchange rate index to dollars : Measures how much a Brazilian Real (R$) is valued in comparison to a dollar.

24363 - Índice de Atividade Econômica do Banco Central - IBC-Br  -- Central Bank economic activity indes: Similar to GPD, but on a monthly basis.

 24369 - Taxa de desocupação - PNADC -- unemployment rate 


```{python}


import os
import urllib.request


interesturl = "https://www3.bcb.gov.br/sgspub/consultarvalores/consultarValoresSeries.do?method=downLoad"

archive_path = "../data/sgsdata.csv"

if not (os.path.exists(archive_path)):
    urllib.request.urlretrieve(interesturl, archive_path)
else:
    print("Data Already Downloaded")

```

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn

```


## Data Transformation

```{python}

df = pd.read_csv(archive_path,sep=";", encoding='latin1')


df = df.rename(columns={'Data':'Date','433 - Índice nacional de preços ao consumidor-amplo (IPCA) - Var. % mensal': 'IPCA', '11753 - Índice da taxa de câmbio real (IPCA) - Jun/1994=100 - Dólar americano - Índice':'Exchange Rate', '20714 - Taxa média de juros das operações de crédito - Total - % a.a.': 'Interest Rate', '24363 - Índice de Atividade Econômica do Banco Central - IBC-Br - Índice': 'GDP', '24369 - Taxa de desocupação - PNADC - %': 'Unemployement Rate'})


df = df.set_index('Date')

df = df.drop(df[df["Exchange Rate"] == '-'].index)
df = df.drop(df[df["Interest Rate"] == '-'].index)
df = df.drop(df[df["Unemployement Rate"] == '-'].index)
df = df.head(len(df)-1)

df = df.replace(r',','.', regex=True)

df['IPCA'] = df['IPCA'].astype(float)
df['Exchange Rate'] = df['Exchange Rate'].astype(float)
df['Interest Rate'] = df['Interest Rate'].astype(float)
df['GDP'] = df['GDP'].astype(float)
df['Unemployement Rate'] = df['Unemployement Rate'].astype(float)


#df.head()
df.shape

```


## Data Understanding

```{python}
sns.lineplot(data=df[0:40], x='Date', y='IPCA')
plt.title('Line Plot of Date vs IPCA')
plt.xlabel('Date')
plt.xticks(rotation=90)
plt.ylabel('IPCA')
plt.show()
plt.close()


sns.lineplot(data=df[0:40], x='Date', y='Exchange Rate')
plt.title('Line Plot of Date vs Exchange Rate')
plt.xlabel('Date')
plt.xticks(rotation=90)
plt.ylabel('Exchange Rate')
plt.show()
plt.close()

sns.lineplot(data=df[0:40], x='Date', y='Interest Rate')
plt.title('Line Plot of Date vs Interest Rate')
plt.xlabel('Date')
plt.xticks(rotation=90)
plt.ylabel('Interest Rate')
plt.show()
plt.close()


sns.lineplot(data=df[0:40], x='Date', y='GDP')
plt.title('Line Plot of Date vs GDP')
plt.xlabel('Date')
plt.xticks(rotation=90)
plt.ylabel('GDP')
plt.show()
plt.close()

sns.lineplot(data=df[0:40], x='Date', y='Unemployement Rate')
plt.title('Line Plot of Date vs Unemployement Rate')
plt.xlabel('Date')
plt.xticks(rotation=90)
plt.ylabel('Unemployement Rates')
plt.show()
plt.close()

```




## First Modeling
```{python}



#Tensor Conversion

X = df.drop(columns=['Interest Rate']).values #X = all expression data

Y = df["Interest Rate"].values #Y = Claudin subtype


X = torch.tensor(X, dtype=torch.float32)
Y = torch.tensor(Y, dtype=torch.float32)


print("Conversion to tensor done")
print(X)

```


```{python}

losslist = []
n_epochs = 5
model = nn.Linear(4, 1)  

# all below as before
loss_func = nn.MSELoss()  
optimizer = torch.optim.SGD(model.parameters()) 

model.train()
for epoch in range(n_epochs):
    y_pred = model(X) 
    loss = loss_func(y_pred, Y)
    losslist.append(loss.item())
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

print("Fitted parameters:")
print("Intercept (bias):", model.bias.item())

## Notice more weights
print("Coefficients (weights):", model.weight.detach().numpy())
print('Loss: ', loss)  
```


```{python}
#loss plot

xs = [x for x in range(len(losslist))]
plt.figure(figsize=(8, 5))
plt.plot(xs, losslist, linewidth=2)
plt.xlabel('Epoch', fontsize=12)
plt.ylabel('Training Loss (Cross-Entropy)', fontsize=12)
plt.title('Deep Learning Model - Training Loss Over Time', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
plt.close()
```